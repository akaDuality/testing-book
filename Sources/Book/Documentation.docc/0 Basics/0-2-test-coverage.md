# Test-coverage

Основная метрика тестирования — тест-кавередж. Разберемся из чего она состоит, как ее интерпретировать и что можно извлечь полезного. 

## Тест-кавередж

Рядом с мифической пирамидой идет и не менее мифический ковередж. 

Общую метрику можно смотреть для прогресса, но вам нужнее его детализация. 


## Метрика для начинающих — количество тестов

Будем честны: до кавереджа надо еще дорасти. Например, Додо Пицце понадобилось более четырех лет, чтобы дойти до метрики в 52%. Поэтому если вы только начинаете тестирование в своей компании, то смотрите просто за количеством тестов. 

Причем важно даже не гнать количество тестов, а смотреть за динамикой: через пару месяце вы поймете с какой скоростью вы пишите тесты и сможете оценивать достаточно ли тестировали в прошедший спринт. 

@Image(source: number-of-tests-in-dynamic)

Спустя время Додо Пицца разделила метрику количества на тип фреймворка, которым команда пишет тесты. Смотрите как интересно: 
- Quick быстро ворвался и позволил написать очень много тестов, но команда от него отказалась, потому что поддерживать такие тесты сложно.
- Swift Testing легко прижился в команде и вместе с LLM тесты легко переписываются с XCTest.

@Image(source: number-of-tests)

@Comment {
    Source: https://buildin.ai/share/52528d4c-57ef-458f-aaa4-534b3a700be7
}

## Ковередж это негативная метрика. 

Допустим, тыщу тестов вы уже написали и пора что-то оценивать на уровне всего проекта. 

Когда мы говорим «тест-ковередж нашего проекта 40%», то имеем в виду «у 60% кода ваще нет никакой автоматизации». Поэтому нам:
- надо уменьшить этот непокрытый процент (т.е. увеличить покрытие тестами)
- мы не знаем насколько качественно протестированы эти 40%, там просто есть хоть какие-то тесты. 

> Tip: ковередж показывает насколько мы справились с хоть каким-то тестированием. 

@Image(source: coverage-in-dynamic)

## Какой тест-кавередж нужен?

Целевого показателя нет, ковередж интересен как метрика в динамике, чтобы понимать успевает ли команда хоть как-то тестировать код автоматически. Он может показать что происходит в проекте, например, мы сильно торопимся редизайнить приложение, а не просели ли тесты? Нет, пишутся даже в повышенном темпе, покрытие растет. Если бы темп замедлился или начал уменьшатся, то это было бы сигналом разобраться в том, что происходит в процессах, но не более. 

@Comment {
    // TODO: показать график
    // TODO: прикинуть расчет по количеству функций и ветвлений. 
}

> Tip: Смотрите на динамику покрытия, а не на итоговую цифру. 

### Когда цель все же нужна

На практике оказалось очень удобно требовать минимальный тест-ковередж на уровне пулл реквеста для измененных файлов. Т.е. общее покрытие проекта может быть процентов 30%, но на уровне пулл реквеста мы требуем, чтобы покрытие не падало ниже этого уровня. Обычно это срабатывает как напоминание, что тесты в целом должны быть внутри пулл реквеста. 

Важно договориться с командой: если тесты в этом пулл реквесте не нужны, то не надо мучаться и писать хоть какие-то, смерджите как есть. Закрепите это правило, а то через несколько лет окажется, что новые разработчики пишут говнотесты, лишь бы ПР зеленый был. 

> Tip: минимальный текст-кавередж удобен на уровне пулл реквеста. 


## Майлстоун для тест-кавереджа

Давайте прикинем какие интересные цифры у кавереджа могут быть. 

Процентов 10-20 кода это основное приложение, которое лишь описывает зависимости и их связи. Скорее всего там нечего особо тестировать, поэтому мы можем не считать эту часть приложения как необходимую к тестированию. Остается 80%.  

Кажется, что ощущение разработчика, что «мы пишем тесты» появляется тогда, когда его код чаще протестирован, чем нет. Значит, наша первая задача — сделать так, чтобы половина самого часто редактируемого кода была покрытам тестами. Два следствия:
- Вам нужно 40-45% покрытия приложения: так разработчики будут чаще натыкаться на протестированный код, чем непротестированный.
- Вам нужно определить какой код меняют чаще всего и с помощью самых сильных разработчиков написать там тесты.  

> Tip: первая цель для ковереджа — 40%. Потом легче будет. 

## Тесты нужны там, где меняется код

Ключевая задача тестов: сохранять требования к коду, чтобы новые *изменения* не сломали старый функционал. Поэтому места, где много разработчиков добавляет разные *требования* к коду должны эти требования и фиксировать. 

> Tip: Если в каких-то местах вы код не меняете, то можно его и не тестировать, че ему ломаться то.   

## Ковередж по модулям в сравнении с размером модулей.

Для тестов критически важно делить приложение на отдельные библиотеки/фреймворки, потому что тесты проще писать на небольшие модули с ограниченным функционалом. Как минимум, вы сможете посмотреть кавередж отдельно по модулям, а это намного интересней: 
- Модули критического пути должны быть протестированы лучше
- Можно сравить частоту изменений с величиной покрытия (должна быть максимальной)
- Могут быть модули полностью без тестов и это нормально (скорее всего там и код никто не меняет)

Но от многомодульности нужно другое: 
- Моментальный билд кода и запуск тестов для того участка кода, с которым работаете. 
- Модуль это смысловая единица, у которого легко отделить инфраструктурные зависимости, можно писать тесты «на фичу» через эти завимости, в итоге вы тестами сможете отвечать на бизнесовые вопросы «а работает ли фича вот так-то». 

- Упорядочить модули по размеру, а потом замерить ковередж. Графики должны совпадать.
- Скорее всего размер совпадает с критичностью, поймете где надо донабрать тестов. 

@Image(source: lines-of-code-coverage)

## Качество покрытия тестами

После достижения хоть каких-то цифр стоит оценить качество тестирования. Нас интересует как много проверок написано относительно одного кусочка кода и насколько качественные эти метрики. 

**Скриншот-тесты**, которые мы генерируем из превью дадут и обширное покрытие тестами (потому что вьюшек много) и могут дать качественное тестирование, потому что мы можем проверять сразу по нескольким направлениям: 
- работа в светлой/темной теме, 
- на разных языках и направлениях текста, 
- проверить доступность разного размера текста и настроек телефона, 
- даже дотянуться до описания, который зачитает скринридер незрячему. 

**UI-тесты** дают качество с другой стороны: они плохо тестируют самое приложение, потому что лишь находят кнопки и нажимают на них, но зато мы можем понять, что модули приложения правильно связаны друг с другом и бэкенд правильно обрабатывает наши сценарии.  

Если сделать шаг в сторону, то нас для каждого экрана интересует насколько протестированы негативные кейсы, ошибки запросов. Можно помечать негативные тесты тегом и сравнивать с количеством запросов к API (но обязательно помодульно, чтобы цифра хоть что-то значила). 

Можно замерять какие виды тестов есть в каждом модуле: 
- скриншот-тесты, 
- на презентационную логику каждого экрана, 
- на сценарий внутри этого модуля. 

Опять же, это можно делать через теги. 

> Tip: Запросто может оказаться, что вам просто подойдет метрика «разработчикам нравятся тесты в этом модуле», а то фиговые тесты иногда хуже, чем никакие: время на поддержку тратят, а пользы не дают. 

### Тест-кавередж Додо Пиццы

@Image(source: test-structure)

**78% — общее покрытие UI- и юнит-тестов** на начала 2025 года. Это негативная метрика, поэтому читать ее надо так: 22% кода не покрыто никакими тестами. Качество покрытия вот этих 78% надо оценивать тем, какие проверки мы умеем делать, но сегодня посмотрим на то из чего состоят эти проценты и какие выводы можно сделать.

**62% кода покрыты UI-тестами.** Это ожидаемо: стоит лишь открыть экран с меню, как сотня классов и тысячи строк пометятся «тест был здесь» и мы очень легко получим высокое, но некачественное покрытие. Если оценивать качество покрытия по регресс-кейсам, то у нас покрыто 62% тест-кейсов. Увы, есть ощущение, что тесткейсов должно быть сильно больше, поэтому кавередж еще может и упасть.

**58% кода покрыто юнит-тестами.** Интересно, что этот замер покрывает и другие участки кода: 16% кода, до которых не дотянулись UI-тесты покрыты юнит-тестами. Тут стоит помнить, что через UI-тесты достаточно сложно проверять разное детальное поведение и негативные кейсы, поэтому юнит-тесты в этом помогают.

Детальная статистка про юниты:

**20% покрытия дают скриншот-тесты!** Пятая часть приложения покрывается тестами верстки, что очень круто, наглядно и достаточно легко делать. Мы используем библиотку от point-free и все эти тесты написали руками. Выходит, что скриншот-тесты это треть покрытия всех юнит-тестов, что очень много.

**6% тестов это автоматически сгенерированные тесты из превьюшек**, нам это делает библиотека Prefire. И вот тут важен еще и наш исторический опыт: мы уже 4.5 года пишем тесты, 3 года как внедрили скриншот-тесты и 4 месяца как используем Prefire. Сейчас он запускает только превьюшки от SwiftUI, но уже дал 6%.

@Comment {
- Как интепретировать покрытие тестами [В телеграмме](https://t.me/RubanovMobile/802)
}
